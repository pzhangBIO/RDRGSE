{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 628)\t1\n",
      "  (1, 158)\t1\n",
      "  (1, 486)\t1\n",
      "  (1, 1097)\t1\n",
      "  (1, 2919)\t1\n",
      "  (1, 2933)\t1\n",
      "  (2, 3285)\t1\n",
      "  (3, 1431)\t1\n",
      "  (3, 3219)\t1\n",
      "  (4, 467)\t1\n",
      "  (5, 648)\t1\n",
      "  (6, 1501)\t1\n",
      "  (7, 1833)\t1\n",
      "  (7, 2137)\t1\n",
      "  (8, 178)\t1\n",
      "  (8, 1033)\t1\n",
      "  (9, 1007)\t1\n",
      "  (10, 1670)\t1\n",
      "  (10, 2622)\t1\n",
      "  (11, 2034)\t1\n",
      "  (12, 113)\t1\n",
      "  (12, 557)\t1\n",
      "  (12, 677)\t1\n",
      "  (12, 794)\t1\n",
      "  (12, 839)\t1\n",
      "  :\t:\n",
      "  (3307, 1969)\t1\n",
      "  (3308, 19)\t1\n",
      "  (3308, 1451)\t1\n",
      "  (3308, 2824)\t1\n",
      "  (3309, 41)\t1\n",
      "  (3310, 116)\t1\n",
      "  (3311, 717)\t1\n",
      "  (3312, 1981)\t1\n",
      "  (3312, 2022)\t1\n",
      "  (3313, 1974)\t1\n",
      "  (3314, 998)\t1\n",
      "  (3315, 645)\t1\n",
      "  (3316, 1181)\t1\n",
      "  (3317, 2911)\t1\n",
      "  (3318, 83)\t1\n",
      "  (3319, 3320)\t1\n",
      "  (3320, 3319)\t1\n",
      "  (3321, 1750)\t1\n",
      "  (3322, 3323)\t1\n",
      "  (3323, 3322)\t1\n",
      "  (3324, 131)\t1\n",
      "  (3324, 268)\t1\n",
      "  (3324, 2820)\t1\n",
      "  (3325, 1643)\t1\n",
      "  (3326, 33)\t1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cos\n",
    "import scipy.sparse as sp\n",
    "from scipy.linalg import fractional_matrix_power, inv\n",
    "\n",
    "\n",
    "def knn(feat, num_node, k, data_name, view_name):\n",
    "    adj = np.zeros((num_node, num_node), dtype=np.int64)\n",
    "    dist = cos(feat)\n",
    "    col = np.argpartition(dist, -(k + 1), axis=1)[:, -(k + 1):].flatten()\n",
    "    adj[np.arange(num_node).repeat(k + 1), col] = 1  \n",
    "    adj = sp.coo_matrix(adj)\n",
    "    sp.save_npz(\"./\"+data_name+\"/\"+view_name+\"_knn.npz\", adj)\n",
    "\n",
    "\n",
    "def adj(adj, data_name, view_name):\n",
    "    adj = sp.coo_matrix(adj)\n",
    "    sp.save_npz(\"./\"+data_name+\"/\"+view_name+\"_adj.npz\", adj)\n",
    "\n",
    "\n",
    "def diff(adj, alpha, data_name, view_name):   \n",
    "    d = np.diag(np.sum(adj, 1))                                    \n",
    "    dinv = fractional_matrix_power(d, -0.5)                       \n",
    "    at = np.matmul(np.matmul(dinv, adj), dinv)                      \n",
    "    adj = alpha * inv((np.eye(adj.shape[0]) - (1 - alpha) * at))   \n",
    "    adj = sp.coo_matrix(adj)\n",
    "    sp.save_npz(\"./\"+data_name+\"/\"+view_name+\"_diff.npz\", adj)\n",
    "\n",
    "data_name = \"citeseer\"\n",
    "view_name = \"v2\"  # v1 or v2\n",
    "view_type = \"knn\"  # knn adj diff\n",
    "\n",
    "adj = sp.load_npz(\"./\"+data_name+\"/ori_adj.npz\")####\n",
    "print(adj)\n",
    "adj.toarray()\n",
    "num_node = adj.shape[0]\n",
    "feat = sp.load_npz(\"./\"+data_name+\"/feat.npz\")\n",
    "feat\n",
    "\n",
    "a = adj.A\n",
    "\n",
    "# if a[0, 0] == 0:\n",
    "#     a += np.eye(num_node)\n",
    "#     print(\"self-loop!\")\n",
    "adj = a\n",
    "view_type = \"knn\" \n",
    "if view_type == \"knn\":  # set k\n",
    "    knn(feat, num_node, 5, data_name, view_name)\n",
    "elif view_type == \"adj\":\n",
    "    adj(adj, data_name, view_name)\n",
    "elif view_type == \"diff\":  # set alpha: 0~1\n",
    "    diff(adj, alpha, data_name, view_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.99999881e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 2.74383004e-01 0.00000000e+00 ... 4.28966787e-05\n",
      "  0.00000000e+00 1.11539050e-05]\n",
      " [0.00000000e+00 0.00000000e+00 5.99999881e-01 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 4.28966787e-05 0.00000000e+00 ... 3.04965500e-01\n",
      "  0.00000000e+00 3.30291619e-07]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  5.99999881e-01 0.00000000e+00]\n",
      " [0.00000000e+00 1.11539050e-05 0.00000000e+00 ... 3.30291619e-07\n",
      "  0.00000000e+00 3.81772145e-01]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def get_khop_indices(k, view):\n",
    "    view = (view.A > 0).astype(\"int32\")\n",
    "    view_ = view\n",
    "    for i in range(1, k):\n",
    "        view_ = (np.matmul(view_, view.T)>0).astype(\"int32\")\n",
    "    view_ = torch.tensor(view_).to_sparse()\n",
    "    return view_.indices()\n",
    "    \n",
    "def topk(k, adj):\n",
    "    pos = np.zeros(adj.shape)\n",
    "    adj=adj.A\n",
    "    print(adj)\n",
    "\n",
    "    for i in range(len(adj)):\n",
    "      one = adj[i].nonzero()[0]\n",
    "      if len(one)>k:\n",
    "        oo = np.argsort(-adj[i, one])\n",
    "        sele = one[oo[:k]]\n",
    "        pos[i, sele] = adj[i, sele]\n",
    "      else:\n",
    "        pos[i, one] = adj[i, one]\n",
    "    return pos\n",
    "\n",
    "#####################\n",
    "## get k-hop scope ##\n",
    "## take citeseer   ##\n",
    "#####################\n",
    "adj = sp.load_npz(\"./citeseer/v1_adj.npz\")\n",
    "indice = get_khop_indices(2, adj)\n",
    "torch.save(indice, \"./citeseer/v1_2.pt\")\n",
    "\n",
    "#####################\n",
    "## get top-k scope ##\n",
    "## take citeseer   ##\n",
    "#####################\n",
    "adj = sp.load_npz(\"./citeseer/v2_diff.npz\")\n",
    "kn = topk(40, adj)\n",
    "kn = sp.coo_matrix(kn)\n",
    "indice = get_khop_indices(1, kn)\n",
    "torch.save(indice, \"./citeseer/v2_40.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature=sp.load_npz(\"./citeseer/feat.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = feature.todense()\n",
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3327"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((np.load(\"./citeseer/label.npy\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "        117, 118, 119]),\n",
       " array([2312, 2313, 2314, 2315, 2316, 2317, 2318, 2319, 2320, 2321, 2322,\n",
       "        2323, 2324, 2325, 2326, 2327, 2328, 2329, 2330, 2331, 2332, 2333,\n",
       "        2334, 2335, 2336, 2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344,\n",
       "        2345, 2346, 2347, 2348, 2349, 2350, 2351, 2352, 2353, 2354, 2355,\n",
       "        2356, 2357, 2358, 2359, 2360, 2361, 2362, 2363, 2364, 2365, 2366,\n",
       "        2367, 2368, 2369, 2370, 2371, 2372, 2373, 2374, 2375, 2376, 2377,\n",
       "        2378, 2379, 2380, 2381, 2382, 2383, 2384, 2385, 2386, 2387, 2388,\n",
       "        2389, 2390, 2391, 2392, 2393, 2394, 2395, 2396, 2397, 2398, 2399,\n",
       "        2400, 2401, 2402, 2403, 2404, 2405, 2406, 2408, 2409, 2410, 2411,\n",
       "        2412, 2413, 2414, 2415, 2416, 2417, 2418, 2419, 2420, 2421, 2422,\n",
       "        2423, 2424, 2425, 2426, 2427, 2428, 2429, 2430, 2431, 2432, 2433,\n",
       "        2434, 2435, 2436, 2437, 2438, 2439, 2440, 2441, 2442, 2443, 2444,\n",
       "        2445, 2446, 2447, 2448, 2449, 2450, 2451, 2452, 2453, 2454, 2455,\n",
       "        2456, 2457, 2458, 2459, 2460, 2461, 2462, 2463, 2464, 2465, 2466,\n",
       "        2467, 2468, 2469, 2470, 2471, 2472, 2473, 2474, 2475, 2476, 2477,\n",
       "        2478, 2479, 2480, 2481, 2482, 2483, 2484, 2485, 2486, 2487, 2488,\n",
       "        2490, 2491, 2492, 2493, 2494, 2495, 2496, 2497, 2498, 2499, 2500,\n",
       "        2501, 2502, 2503, 2504, 2505, 2506, 2507, 2508, 2509, 2510, 2511,\n",
       "        2512, 2513, 2514, 2515, 2516, 2517, 2518, 2519, 2520, 2521, 2522,\n",
       "        2523, 2524, 2525, 2526, 2527, 2528, 2529, 2530, 2531, 2532, 2533,\n",
       "        2534, 2535, 2536, 2537, 2538, 2539, 2540, 2541, 2542, 2543, 2544,\n",
       "        2545, 2546, 2547, 2548, 2549, 2550, 2551, 2552, 2554, 2555, 2556,\n",
       "        2557, 2558, 2559, 2560, 2561, 2562, 2563, 2564, 2565, 2566, 2567,\n",
       "        2568, 2569, 2570, 2571, 2572, 2573, 2574, 2575, 2576, 2577, 2578,\n",
       "        2579, 2580, 2581, 2582, 2583, 2584, 2585, 2586, 2587, 2588, 2589,\n",
       "        2590, 2591, 2592, 2593, 2594, 2595, 2596, 2597, 2598, 2599, 2600,\n",
       "        2601, 2602, 2603, 2604, 2605, 2606, 2607, 2608, 2609, 2610, 2611,\n",
       "        2612, 2613, 2614, 2615, 2616, 2617, 2618, 2619, 2620, 2621, 2622,\n",
       "        2623, 2624, 2625, 2626, 2627, 2628, 2629, 2630, 2631, 2632, 2633,\n",
       "        2634, 2635, 2636, 2637, 2638, 2639, 2640, 2641, 2642, 2643, 2644,\n",
       "        2645, 2646, 2647, 2648, 2649, 2650, 2651, 2652, 2653, 2654, 2655,\n",
       "        2656, 2657, 2658, 2659, 2660, 2661, 2662, 2663, 2664, 2665, 2666,\n",
       "        2667, 2668, 2669, 2670, 2671, 2672, 2673, 2674, 2675, 2676, 2677,\n",
       "        2678, 2679, 2680, 2681, 2683, 2684, 2685, 2686, 2687, 2688, 2689,\n",
       "        2690, 2691, 2692, 2693, 2694, 2695, 2696, 2697, 2698, 2699, 2700,\n",
       "        2701, 2702, 2703, 2704, 2705, 2706, 2707, 2708, 2709, 2710, 2711,\n",
       "        2712, 2713, 2714, 2715, 2716, 2717, 2718, 2719, 2720, 2721, 2722,\n",
       "        2723, 2724, 2725, 2726, 2727, 2728, 2729, 2730, 2731, 2732, 2733,\n",
       "        2734, 2735, 2736, 2737, 2738, 2739, 2740, 2741, 2742, 2743, 2744,\n",
       "        2745, 2746, 2747, 2748, 2749, 2750, 2751, 2752, 2753, 2754, 2755,\n",
       "        2756, 2757, 2758, 2759, 2760, 2761, 2762, 2763, 2764, 2765, 2766,\n",
       "        2767, 2768, 2769, 2770, 2771, 2772, 2773, 2774, 2775, 2776, 2777,\n",
       "        2778, 2779, 2780, 2782, 2783, 2784, 2785, 2786, 2787, 2788, 2789,\n",
       "        2790, 2791, 2792, 2793, 2794, 2795, 2796, 2797, 2798, 2799, 2800,\n",
       "        2801, 2802, 2803, 2804, 2805, 2806, 2807, 2808, 2809, 2810, 2811,\n",
       "        2812, 2813, 2814, 2815, 2816, 2817, 2818, 2819, 2820, 2821, 2822,\n",
       "        2823, 2824, 2825, 2826, 2827, 2828, 2829, 2830, 2831, 2832, 2833,\n",
       "        2834, 2835, 2836, 2837, 2838, 2839, 2840, 2841, 2842, 2843, 2844,\n",
       "        2845, 2846, 2847, 2848, 2849, 2850, 2851, 2852, 2853, 2854, 2855,\n",
       "        2856, 2857, 2858, 2859, 2860, 2861, 2862, 2863, 2864, 2865, 2866,\n",
       "        2867, 2868, 2869, 2870, 2871, 2872, 2873, 2874, 2875, 2876, 2877,\n",
       "        2878, 2879, 2880, 2881, 2882, 2883, 2884, 2885, 2886, 2887, 2888,\n",
       "        2889, 2890, 2891, 2892, 2893, 2894, 2895, 2896, 2897, 2898, 2899,\n",
       "        2900, 2901, 2902, 2903, 2904, 2905, 2906, 2907, 2908, 2909, 2910,\n",
       "        2911, 2912, 2913, 2914, 2915, 2916, 2917, 2918, 2919, 2920, 2921,\n",
       "        2922, 2923, 2924, 2925, 2926, 2927, 2928, 2929, 2930, 2931, 2932,\n",
       "        2933, 2934, 2935, 2936, 2937, 2938, 2939, 2940, 2941, 2942, 2943,\n",
       "        2944, 2945, 2946, 2947, 2948, 2949, 2950, 2951, 2952, 2954, 2955,\n",
       "        2956, 2957, 2958, 2959, 2960, 2961, 2962, 2963, 2964, 2965, 2966,\n",
       "        2967, 2968, 2969, 2970, 2971, 2972, 2973, 2974, 2975, 2976, 2977,\n",
       "        2978, 2979, 2980, 2981, 2982, 2983, 2984, 2985, 2986, 2987, 2988,\n",
       "        2989, 2990, 2991, 2992, 2993, 2994, 2995, 2996, 2997, 2998, 2999,\n",
       "        3000, 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, 3009, 3010,\n",
       "        3011, 3012, 3013, 3014, 3015, 3016, 3017, 3018, 3019, 3020, 3021,\n",
       "        3022, 3023, 3024, 3025, 3026, 3027, 3028, 3029, 3030, 3031, 3032,\n",
       "        3033, 3034, 3035, 3036, 3037, 3038, 3039, 3040, 3041, 3043, 3044,\n",
       "        3045, 3046, 3047, 3048, 3049, 3050, 3051, 3052, 3053, 3054, 3055,\n",
       "        3056, 3057, 3058, 3059, 3060, 3061, 3062, 3064, 3065, 3066, 3067,\n",
       "        3068, 3069, 3070, 3071, 3072, 3073, 3074, 3075, 3076, 3077, 3078,\n",
       "        3079, 3080, 3081, 3082, 3083, 3084, 3085, 3086, 3087, 3088, 3089,\n",
       "        3090, 3091, 3092, 3093, 3094, 3095, 3096, 3097, 3098, 3099, 3100,\n",
       "        3101, 3102, 3103, 3104, 3105, 3106, 3107, 3108, 3109, 3110, 3111,\n",
       "        3112, 3113, 3114, 3115, 3116, 3117, 3118, 3119, 3120, 3121, 3122,\n",
       "        3123, 3124, 3125, 3126, 3127, 3128, 3129, 3130, 3131, 3132, 3133,\n",
       "        3134, 3135, 3136, 3137, 3138, 3139, 3140, 3141, 3142, 3143, 3144,\n",
       "        3145, 3146, 3147, 3148, 3149, 3150, 3151, 3152, 3153, 3154, 3155,\n",
       "        3156, 3157, 3158, 3159, 3160, 3161, 3162, 3163, 3164, 3165, 3166,\n",
       "        3167, 3168, 3169, 3170, 3171, 3172, 3173, 3174, 3175, 3176, 3177,\n",
       "        3178, 3179, 3180, 3181, 3182, 3183, 3184, 3185, 3186, 3187, 3188,\n",
       "        3189, 3190, 3191, 3192, 3193, 3194, 3195, 3196, 3197, 3198, 3199,\n",
       "        3200, 3201, 3202, 3203, 3204, 3205, 3206, 3207, 3208, 3209, 3210,\n",
       "        3211, 3213, 3215, 3216, 3217, 3218, 3219, 3220, 3221, 3222, 3223,\n",
       "        3224, 3225, 3226, 3227, 3228, 3229, 3230, 3231, 3232, 3233, 3234,\n",
       "        3235, 3236, 3237, 3238, 3239, 3240, 3241, 3242, 3243, 3244, 3245,\n",
       "        3246, 3247, 3248, 3249, 3251, 3252, 3253, 3254, 3255, 3256, 3257,\n",
       "        3258, 3259, 3260, 3261, 3262, 3263, 3264, 3265, 3266, 3267, 3268,\n",
       "        3269, 3270, 3271, 3272, 3273, 3274, 3275, 3276, 3277, 3278, 3279,\n",
       "        3280, 3281, 3282, 3283, 3284, 3285, 3286, 3287, 3288, 3289, 3290,\n",
       "        3291, 3293, 3294, 3295, 3296, 3297, 3298, 3299, 3300, 3301, 3302,\n",
       "        3303, 3304, 3307, 3308, 3310, 3311, 3312, 3313, 3314, 3315, 3316,\n",
       "        3317, 3318, 3319, 3320, 3321, 3322, 3323, 3324, 3325, 3326]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(\"./citeseer/train.npy\"),np.load(\"./citeseer/test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3327x3327 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 19962 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.load_npz(\"./citeseer/v2_knn.npz\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    1,  ..., 3326, 3326, 3326],\n",
       "        [   0,  628,    1,  ..., 3193, 3197, 3326]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(\"./citeseer/v1_2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0fa3dc3e6290d9c3ddb80acf8355d8b7784237d19d97bf24d9b1ba8fe238dcf3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
